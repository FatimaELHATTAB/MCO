# SPLINK 
# ==============================================================

# Partie 1 : Comprendre comment fonctionne Splink
# -----------------------------------------------
"""
Splink est une librairie open-source d√©velopp√©e par le Ministry of Justice du Royaume-Uni. Elle permet de faire de la d√©tection de doublons et de la correspondance entre entit√©s dans de grands jeux de donn√©es, m√™me en pr√©sence de variations ou d'erreurs (fuzzy matching).

### Fonctionnement global (avec exemples) :
- Splink cr√©e toutes les paires possibles de lignes entre deux datasets (ou dans un m√™me dataset pour les doublons)
    ‚û§ Exemple : 10 000 lignes dans chaque dataset ‚Üí 100 millions de paires (10k x 10k)

- Il applique des r√®gles de "blocking" pour √©viter la combinatoire explosive
    ‚û§ Exemple : si on bloque sur le pays (FR uniquement), on r√©duit √† ~1 million de paires pertinentes

- Il compare les colonnes en utilisant diff√©rentes m√©thodes (exact match, Jaro-Winkler, Levenshtein, etc.)
    ‚û§ Exemple : comparer "BNP Paribas" √† "BNP Paribas SA" avec JaroWinkler ‚Üí score 0.96

- Il utilise un mod√®le probabiliste de type Fellegi-Sunter pour calculer une **probabilit√© de correspondance** pour chaque paire
    ‚û§ Exemple : une paire peut avoir une probabilit√© de match = 0.94 si les noms et pays correspondent mais pas l'ISIN

- Il regroupe les paires match√©es en **clusters d'entit√©s uniques** (cha√Ænage transitif ou composantes connexes)
    ‚û§ Exemple : si A=B et B=C, alors A, B et C seront dans le m√™me cluster

### Probabilit√©s utilis√©es :
- **m-probabilit√©** : probabilit√© qu'un champ soit √©gal si les deux lignes sont un vrai match
- **u-probabilit√©** : probabilit√© qu'un champ soit √©gal par hasard si les lignes ne matchent pas
- Le **score log(m/u)** donne un poids d'information pour chaque comparaison

---

# Partie 1 bis : Algorithme EM (Expectation-Maximization)

L‚Äôalgorithme EM est utilis√© par Splink pour **estimer automatiquement les probabilit√©s m et u** √† partir des donn√©es.

- **√âtape 1 ‚Äì Initialisation** : Splink fait une hypoth√®se initiale na√Øve sur les matches probables
- **√âtape 2 ‚Äì E-step (Expectation)** : √† partir des poids, il estime les probabilit√©s de match de chaque paire
- **√âtape 3 ‚Äì M-step (Maximization)** : √† partir des matches estim√©s, il r√©ajuste les m/u pour chaque niveau de comparaison
- **R√©p√®te** jusqu‚Äô√† convergence

‚û§ Exemple : au bout de 5 it√©rations, Splink comprend que "Total" et "TotalEnergies" sont souvent li√©s, et ajuste le poids de cette ressemblance

---

# Partie 1 ter : Performance et Scalabilit√©

Splink est con√ßu pour des cas d‚Äôusage √† grande √©chelle. Ses performances d√©pendent de trois leviers principaux :

### 1. **Blocking Rules**
R√©duisent le nombre de comparaisons n√©cessaires. Sans blocking, comparer 1M √ó 1M = 1 trillion de paires. Avec un bon blocking (ex : m√™me pays), on peut ramener √ßa √† 5M ou 10M.

### 2. **Backend moteur SQL (DuckDB, Spark)**
- **DuckDB** (par d√©faut) : parfait pour prototypage local et datasets < 10 millions de lignes
- **Spark** : permet d'ex√©cuter Splink sur des clusters distribu√©s pour g√©rer des dizaines ou centaines de millions de lignes

### 3. **Structure en paires + vectorisation**
Splink ne compare pas des lignes na√Øvement. Il transforme les paires en vecteurs de comparaison (ex : 1 si √©gal, 0.8 si proche, etc.) et les combine de fa√ßon math√©matiquement optimis√©e

### Exemple concret :
| Volume initial | Blocking appliqu√©     | Comparaisons finales |
|----------------|------------------------|----------------------|
| 10 000 √ó 10 000| sur `country`, `LEI`   | ‚âà 1 200 000          |
| 1 000 000 √ó 1 000 000| aucun blocking | ‚âà 1 000 000 000 000 (infaisable)

Conclusion : **bien d√©finir ses rules de blocking** est la cl√© pour tirer le meilleur de Splink √† l‚Äô√©chelle

---

### Comparaison des deux √©l√©ments cl√©s :

| √âl√©ment             | blocking_rules                                 | comparison_columns                              |
|---------------------|--------------------------------------------------|---------------------------------------------------|
| R√¥le                | R√©duit le nombre de paires √† comparer            | Calcule un score ou une distance                  |
| Syntaxe             | SQL-like condition entre l. et r.                | Fonctions Splink (ExactMatch, JaroWinkler, ...)  |
| Appliqu√© quand ?    | En premier, avant toute comparaison              | Ensuite, sur les paires retenues                  |
| But principal       | Optimiser les perfs, √©viter les combinaisons inutiles | D√©cider si deux lignes repr√©sentent le m√™me objet |

### M√©thodes de comparaison possibles :
- **ExactMatch** : √©galit√© stricte (string, code, etc.)
- **JaroWinkler** : distance floue pour noms proches (Michel/Michele)
- **LevenshteinAtThresholds** : tol√©rance aux typos avec seuils
- **ArrayIntersect** : pour listes de valeurs (tags, codes multiples)
- **TermFrequencyAdjustedExactMatch** : prend en compte la fr√©quence du terme (TF-IDF)



# üß† Comparatif des M√©thodes d'Entity Resolution

## 1. üóÇÔ∏è Tableau comparatif global

| M√©thode          | Approche                 | Supervision       | Scalabilit√©      | Fuzzy Matching | Limites cl√©s |
|------------------|--------------------------|-------------------|------------------|----------------|--------------|
| **Splink**       | Probabiliste (Fellegi-Sunter) + r√®gles | ‚ùå Non supervis√© | ‚úÖ‚úÖ‚úÖ Spark/DuckDB | ‚úÖ‚úÖ (via distances textuelles) | Setup initial complexe, JSON √† configurer |
| **dedupe**       | Apprentissage actif (r√©gression logistique) | ‚úÖ Semi-supervis√© | ‚úÖ (limit√© au RAM, <20M) | ‚úÖ‚úÖ‚úÖ (TF-IDF, Levenshtein, etc.) | N√©cessite annotation manuelle initiale |
| **RecordLinkage**| R√®gles + probabiliste    | ‚ùå Non supervis√©  | ‚ùå (<1M lignes recommand√©) | ‚úÖ (simple) | RAM-bound, lent pour gros volumes |
| **Zingg**        | Active learning + Spark  | ‚úÖ Semi-supervis√© | ‚úÖ‚úÖ Spark-native  | ‚úÖ‚úÖ            | Moins connu, moins document√© |
| **DeepMatcher**  | Deep Learning supervis√©  | ‚úÖ‚úÖ Supervision forte | ‚ùå (besoin GPU, gros dataset) | ‚úÖ‚úÖ‚úÖ | Donn√©es annot√©es massives requises |
| **FastLink**     | Probabiliste (Fellegi)   | ‚ùå Non supervis√©  | ‚úÖ (R-based)      | ‚úÖ              | Moins adapt√© √† Python / pipelines ML |
| **PyJedAI**      | Ensemble hybride         | ‚úÖ                | ‚úÖ                | ‚úÖ              | Plus acad√©mique, peu int√©gr√© aux pipelines |

---

## 2. ‚úÖ  Splink/dedupe 

| Crit√®re m√©tier / technique                   | Raisons de pertinence |
|---------------------------------------------|------------------------|
| **Volum√©trie √©lev√©e (100M+ lignes)**         | Seuls Splink (Spark/DuckDB) ou Zingg le g√®rent bien |
| **R√®gles m√©tiers explicites (ex: ISIN, LEI)**| Splink permet de coder des `comparison_levels` tr√®s pr√©cises |
| **1 seul champ √† fuzzy matcher**            | Splink et dedupe g√®rent tr√®s bien cela (Jaro-Winkler, TF-IDF‚Ä¶) |
| **Besoin de scoring et cluster_id en sortie**| Les deux outils produisent des scores et des clusters interpr√©tables |
| **Pipeline reproductible et industrialisable**| Splink a une structure plus robuste pour l'industrialisation |
| **Pas besoin d‚Äôun mod√®le black-box**        | Splink offre une explicabilit√© m√©tier claire |
| **Possibilit√© de supervision l√©g√®re**        | dedupe permet d‚Äôapprendre √† partir de peu d‚Äôannotations |

---

## 3. ü§ú Splink vs ü§õ dedupe 

| Crit√®re                            | **Splink**                                      | **dedupe**                                   |
|------------------------------------|-------------------------------------------------|-----------------------------------------------|
| **Approche**                       | Mod√®le probabiliste statique (Fellegi-Sunter)  | Apprentissage semi-supervis√© (r√©gression logistique) |
| **Fuzzy matching**                 | Comparisons manuelles (Jaro-Winkler, etc.)     | Automatique via apprentissage                 |
| **R√®gles exactes (ISIN, LEI, etc.)**| D√©finies explicitement dans les settings       | Apprises si tu as annot√© des exemples         |
| **Scalabilit√©**                    | ‚úÖ Spark / DuckDB pour des millions de lignes  | ‚ùå RAM-bound (~1-10M lignes max efficacement)  |
| **Supervision**                    | ‚ùå Aucune (logique d√©clarative uniquement)      | ‚úÖ Annotation active (match / non-match)       |
| **Blocking (r√©duction de la combinatoire)** | ‚úÖ Tr√®s flexible, obligatoire et optimis√©     | ‚úÖ Automatique ou manuel, mais moins flexible  |
| **Explicabilit√©**                  | ‚úÖ Tr√®s √©lev√©e (chaque r√®gle est lisible)       | Moyenne (poids appris, moins lisibles)        |
| **Mise en production**             | ‚úÖ Ex√©cution SQL, pipeline industrialisable     | ‚úÖ Possible en script Python, mod√®le exportable |
| **Setup initial**                  | ‚ùå Plus complexe (`settings.json`)              | ‚úÖ Simple √† configurer                         |
| **Prise en main rapide**           | ‚ùå Apprentissage n√©cessaire                     | ‚úÖ Rapide, tr√®s bon pour POC                   |

---

## üèÜ  quel outil choisir ?

| Situation typique | Outil recommand√© |
|-------------------|------------------|
| **Gros volume de donn√©es (100M+), r√®gles pr√©cises, un champ flou, pipeline ma√Ætris√© et tra√ßable** | ‚úÖ‚úÖ **Splink** |
| **Dataset < 10M lignes, champ flou difficile, besoin d‚Äôun apprentissage intelligent, POC rapide** | ‚úÖ **dedupe** |
| **Besoin d‚Äôun pipeline long terme, compatible Spark ou SQL, exportable et explicable** | ‚úÖ‚úÖ **Splink** |

---





