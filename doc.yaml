from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Iterator, Mapping, Optional, Tuple

import polars as pl
import psycopg2
import yaml


# ---------- Config models (simple V1) ----------

@dataclass(frozen=True)
class DatasetSpec:
    query: str
    schema_yaml: Dict[str, str]  # e.g. {"col": "Utf8"}; OPTIONAL in YAML


@dataclass(frozen=True)
class ProviderSpec:
    provider: str
    chunk_size: int
    params_defaults: Dict[str, Any]
    normalized: DatasetSpec
    identity: DatasetSpec
    matching: Dict[str, Any]  # stored for later use


def _yaml_to_polars_schema(schema_yaml: Mapping[str, str]) -> Dict[str, pl.DataType]:
    out: Dict[str, pl.DataType] = {}
    for col, dtype_name in schema_yaml.items():
        try:
            out[col] = getattr(pl, str(dtype_name))
        except AttributeError as e:
            raise ValueError(f"Unknown Polars dtype '{dtype_name}' for column '{col}'") from e
    return out


def _load_provider_spec(config_dir: str | Path, provider: str) -> ProviderSpec:
    path = Path(config_dir) / f"{provider}.yaml"
    raw = yaml.safe_load(path.read_text(encoding="utf-8")) or {}

    if raw.get("provider") != provider:
        raise ValueError(f"Config provider mismatch in {path}: expected '{provider}'")

    read_cfg = raw.get("read") or {}
    chunk_size = int(read_cfg.get("chunk_size", 50_000))
    params_defaults = read_cfg.get("params_defaults") or {}

    datasets = raw.get("datasets") or {}
    if "normalized" not in datasets or "identity" not in datasets:
        raise ValueError(f"Missing datasets.normalized or datasets.identity in {path}")

    def parse_dataset(ds: dict) -> DatasetSpec:
        q = (ds.get("query") or "").strip()
        if not q:
            raise ValueError(f"Empty dataset query in {path}")
        schema_yaml = ds.get("schema") or {}  # OPTIONAL (smart fallback)
        return DatasetSpec(query=q, schema_yaml=schema_yaml)

    matching = raw.get("matching") or {}

    return ProviderSpec(
        provider=provider,
        chunk_size=chunk_size,
        params_defaults=params_defaults,
        normalized=parse_dataset(datasets["normalized"]),
        identity=parse_dataset(datasets["identity"]),
        matching=matching,
    )


# ---------- DB Reader (chunked) using psycopg2 ----------

def _iter_query_chunks(
    conn: psycopg2.extensions.connection,
    query: str,
    params: Mapping[str, Any],
    schema: Optional[Dict[str, pl.DataType]],
    chunk_size: int,
) -> Iterator[pl.DataFrame]:
    """
    Uses a server-side named cursor (psycopg2) to stream results in batches.
    """
    # Named cursor => server-side cursor
    cur = conn.cursor(name="cur_polars")
    try:
        cur.execute(query, params)

        colnames = [desc[0] for desc in cur.description]  # psycopg2: tuple metadata

        while True:
            rows = cur.fetchmany(chunk_size)
            if not rows:
                break

            df = pl.DataFrame(rows, schema=colnames)

            # If schema provided, cast (non-strict to avoid hard failures on nulls)
            if schema:
                df = df.cast(schema, strict=False)

            yield df
    finally:
        cur.close()


def _read_query_as_df(
    conn: psycopg2.extensions.connection,
    query: str,
    params: Mapping[str, Any],
    schema: Optional[Dict[str, pl.DataType]],
    chunk_size: int,
) -> pl.DataFrame:
    chunks = list(_iter_query_chunks(conn, query, params, schema, chunk_size))
    if not chunks:
        # empty DF with schema if available
        return pl.DataFrame(schema=schema or {})
    return pl.concat(chunks, how="vertical", rechunk=True)


# ---------- DataLoader ----------

class DataLoader:
    """
    V1: DataLoader(provider) -> (df_normalized, df_identity)
    SQL queries live in configs/providers/<provider>.yaml
    """

    def __init__(self, dsn: str, config_dir: str | Path) -> None:
        self._dsn = dsn
        self._config_dir = Path(config_dir)

    def load(
        self,
        provider: str,
        params_override: Optional[Mapping[str, Any]] = None,
    ) -> Tuple[pl.DataFrame, pl.DataFrame]:
        spec = _load_provider_spec(self._config_dir, provider)

        # merge params defaults + overrides
        params: Dict[str, Any] = dict(spec.params_defaults)
        if params_override:
            params.update(params_override)

        norm_schema = _yaml_to_polars_schema(spec.normalized.schema_yaml) if spec.normalized.schema_yaml else None
        ident_schema = _yaml_to_polars_schema(spec.identity.schema_yaml) if spec.identity.schema_yaml else None

        # autocommit off by default; fine for reads
        conn = psycopg2.connect(self._dsn)
        try:
            # optional: read-only + safer session settings
            conn.set_session(readonly=True, autocommit=False)

            df_normalized = _read_query_as_df(
                conn=conn,
                query=spec.normalized.query,
                params=params,
                schema=norm_schema,
                chunk_size=spec.chunk_size,
            )
            df_identity = _read_query_as_df(
                conn=conn,
                query=spec.identity.query,
                params=params,
                schema=ident_schema,
                chunk_size=spec.chunk_size,
            )

            return df_normalized, df_identity
        finally:
            conn.close()

    def get_matching_config(self, provider: str) -> Dict[str, Any]:
        """
        Matching rules live in the same provider YAML under `matching`.
        """
        spec = _load_provider_spec(self._config_dir, provider)
        return spec.matching




provider: rcx

read:
  chunk_size: 50000
  params_defaults:
    # tu peux ajouter country/from_date plus tard
    # country: null
    # from_date: "2026-01-01"
    {}

datasets:
  normalized:
    query: |
      SELECT
          le.local_id,
          le.flux_source,
          le.company_name,
          le.company_name_clean,
          STRING_AGG(DISTINCT ci.company_identifier, '|'
                     ORDER BY ci.company_identifier)
              FILTER (WHERE ci.company_identifier_nature = 'N') AS national_registry,
          STRING_AGG(DISTINCT ci.company_identifier, '|'
                     ORDER BY ci.company_identifier)
              FILTER (WHERE ci.company_identifier_nature = 'I') AS international_registry
      FROM own_91109_svg_um.legal_entity_normalized le
      LEFT JOIN own_91109_svg_um.company_identifier_normalized ci
        ON  ci.local_id    = le.local_id
        AND ci.flux_source = le.flux_source
      GROUP BY
          le.local_id, le.flux_source, le.company_name, le.company_name_clean;

    # schema est OPTIONNEL (recommand√©, mais pas obligatoire)
    schema:
      local_id: Utf8
      flux_source: Utf8
      company_name: Utf8
      company_name_clean: Utf8
      national_registry: Utf8
      international_registry: Utf8

  identity:
    query: |
      SELECT
          le.tpn_id,
          le.company_name,
          le.company_name_clean,
          STRING_AGG(DISTINCT ci.company_identifier, '|'
                     ORDER BY ci.company_identifier)
              FILTER (WHERE ci.company_identifier_nature = 'N') AS national_registry,
          STRING_AGG(DISTINCT ci.company_identifier, '|'
                     ORDER BY ci.company_identifier)
              FILTER (WHERE ci.company_identifier_nature = 'I') AS international_registry
      FROM own_91109_svg_um.legal_entity le
      LEFT JOIN own_91109_svg_um.company_identifier ci
        ON  ci.tpn_id = le.tpn_id
      GROUP BY le.tpn_id, le.company_name, le.company_name_clean;

    schema:
      tpn_id: Utf8
      company_name: Utf8
      company_name_clean: Utf8
      national_registry: Utf8
      international_registry: Utf8

matching:
  join_keys:
    - name: international_registry_token
      left: international_registry
      right: international_registry
      method: token_overlap_pipe
      weight: 1.0

  rules:
    - name: fuzzy_company_name_clean
      type: fuzzy
      left: company_name_clean
      right: company_name_clean
      algo: jaro_winkler
      threshold: 0.92
      weight: 0.6


