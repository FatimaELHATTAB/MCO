Synthèse Technique – Revue critique de la solution de matching Python et justification des choix vis-à-vis de Java

1. Contexte et objectif

La solution actuelle de matching d'entités a été conçue sous Python dans une logique de prototypage rapide. Elle vise à réconcilier des bases de tiers (RMPM, fournisseurs externes) selon des critères paramétrables, avec gestion des doublons, du fuzzy matching et du clustering. Ce document propose une évaluation critique de cette implémentation, une comparaison argumentée avec les standards Java, et des pistes concrètes d'évolution.

2. Points positifs techniques de la solution actuelle

Domaine

Détails approfondis

Performance et scalabilité

L’usage de Polars, moteur de traitement en mémoire en Rust, a permis une exécution hautement performante sur plusieurs millions de lignes avec un faible encombrement mémoire. Les benchmarks internes ont montré un gain significatif par rapport à Pandas ou Spark pour des traitements unitaires.

Flexibilité métier

La logique de matching est structurée autour de niveaux déclaratifs dans un fichier YAML, permettant une personnalisation rapide des règles métier sans modifier le code. Cela facilite l’adaptation par les équipes fonctionnelles ou en phase de recette.

Pré-intégration SI

Connexions bases de données isolées dans des modules réutilisables (get_credentials, Connection). Gestion multi-fournisseurs centralisée (filtrage conditionnel sur pays, sources, etc.), avec scripts batch exécutables et configuration reproductible.

Agilité de développement

Python a permis de livrer une première version fonctionnelle en un temps court, avec des itérations fréquentes et un retour rapide des utilisateurs métiers. Le cycle de feedback est court grâce à la souplesse du langage et des outils associés.

--------|---------|
| Performance et scalabilité | Utilisation de Polars pour un traitement en mémoire rapide et efficace sur gros volumes. |
| Flexibilité métier | Matching par niveaux configurables via YAML ; support du fuzzy matching. |
| Pré-intégration SI | Connexions isolées en module, multi-fournisseurs gérés, scripts d'exécution disponibles. |

3. Limites techniques majeures identifiées et critiques approfondies du code actuel

Limite

Analyse détaillée et critique experte

Couplage fort

Le code regroupe dans un seul bloc l’ingestion, le traitement, le matching et l’export. Par exemple, la fonction main() dans matching_prod_algorithm.py est un script linéaire difficilement testable, non réutilisable dans d'autres contextes (streaming, API, batch). Il aurait fallu structurer chaque brique comme un composant injectable/testable.

Matching rigide, heuristique

La logique de matching par niveaux est déclarative mais manque d'adaptabilité. Chaque niveau repose sur une jointure exacte ou fuzzy manuelle, sans pondération dynamique, ni scoring explicite, ni validation croisée. Cela empêche toute optimisation data-driven.

Pas d’évaluation de la qualité du matching

Aucun indicateur de précision, rappel, ou F1 score n’est calculé. Le matching est appliqué de manière binaire sans validation, ce qui est problématique pour la prise de décision métier.

Pas de typage, ni validation des données

Les entrées du système ne sont pas validées formellement. Aucun modèle de données ou schéma explicite (ex: Pydantic, Marshmallow) n’est défini, ce qui ouvre la porte à des incohérences silencieuses.

Absence d’orchestration robuste

Le pipeline repose sur des boucles Python manuelles. En cas d’échec à un niveau, le processus ne redémarre pas proprement. Aucun mécanisme de réexécution transactionnelle ou de retry contrôlé n’est présent.

--------|--------------------------------------|
| Couplage fort | L’absence de séparation stricte entre extraction, transformation, matching et export rend le pipeline rigide et peu évolutif. Toute modification dans une étape peut affecter le tout. Difficile à maintenir en équipe. |
| Absence de tests et CI | Aucun test unitaire ou de non-régression n’est en place. Les modifications se font sans filet de sécurité. Cela introduit un risque élevé en production, et empêche une montée de version maîtrisée. |
| Manque d’explicabilité | Le résultat du matching est binaire, sans score ni logique explicable : difficile pour les métiers de comprendre pourquoi une entité est liée à une autre. Cela nuit à l’acceptabilité métier et à l’auditabilité. |
| Documentation lacunaire | Peu de docstrings, pas de README technique structuré, pas de génération automatique. La compréhension du code dépend entièrement des développeurs initiaux. |
| Pas de traçabilité ou logs structurés | L’absence de journalisation métier ou technique fine rend difficile le débogage, le suivi et le contrôle qualité. |

--------|--------|
| Couplage fort | Difficulté à tester ou remplacer des briques de traitement indépendamment. |
| Absence de tests et CI | Aucune couverture de code, validation manuelle uniquement. |
| Manque d’explicabilité | Pas de scores ni de justification sur les liens identifiés. |
| Documentation lacunaire | Difficile à reprendre, aucune génération automatisée. |



5. Recommandations concrètes d'évolution avec vision étendue

Axe d'amélioration

Valeur technique, alignement avec standards Java et opportunités spécifiques à Python

Modularisation du pipeline

Permet une isolation des responsabilités, des tests unitaires par composant, et l’orchestration via Airflow. Approche inspirée du design Spring Boot avec injection de dépendances mais plus rapide à implémenter sous Python.

Adoption d’un moteur de matching explicable

Splink offre une implémentation du modèle de Fellegi-Sunter. On y retrouve le scoring, la gestion des incertitudes, le clustering — des éléments critiques dans un système auditable. Intégration naturelle via DataFrames Polars/Pandas.

Passage au matching sémantique vectoriel

Python permet d'exploiter sentence-transformers, FAISS, Weaviate pour comparer les entités sur une base sémantique. Cela ouvre des perspectives inaccessibles sans bibliothèques externes complexes en Java.

Architecture plug & play via typage et validation

Utilisation de pydantic pour typer et valider chaque étape (entrée, sortie, modèles de matching). Aligné sur l’approche Java (beans + annotations), avec une syntaxe bien plus expressive et ergonomique.

CI/CD, qualité et sécurité

Linters, coverage, typage statique, SAST, scan de dépendances — tout cela est disponible sous Python avec tox, bandit, mypy, GitHub Actions. La stack de qualité est au niveau attendu dans une chaîne Java industrielle.

Monitoring natif et auditabilité

Couplage avec structlog, prometheus_client, génération de rapports en sortie JSON/CSV pour audit métier. Ce niveau de visibilité est souvent sous-estimé dans les scripts Python, mais est essentiel pour atteindre les standards Java.

La solution actuelle montre que Python est un écosystème apte à produire des pipelines robustes, performants et orientés métier. Les difficultés observées (tests, traçabilité, documentation) ne sont pas liées à des limitations du langage, mais à un niveau d'exigence d'implémentation encore perfectible.

Là où Java impose une rigueur formelle dès les premières lignes, Python offre une souplesse qui doit être encadrée par des pratiques outillées. Avec l’ajout de tests structurés, de typage statique, d’un moteur de matching probabiliste comme Splink, et d’outils IA modernes pour le fuzzy matching sémantique, la solution peut dépasser ce qu’un équivalent Java permettrait, en termes de rapidité, d’enrichissement algorithmique et de retour métier.

Plutôt qu’une réécriture, une consolidation de la base Python actuelle avec les standards de qualité logicielle est une trajectoire plus réaliste, maîtrisable, et tournée vers l’avenir.

Python n'est pas un frein à la rigueur logicielle. La dette technique actuelle est due à un développement rapide, non à des limitations du langage.
Avec des outils comme pytest, mypy, Sphinx, Splink ou même des modèles IA de nouvelle génération, on peut égaler, voire dépasser les standards Java en termes de testabilité, maintenabilité, explicabilité et adaptation aux cas complexes.

